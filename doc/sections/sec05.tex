\section{Conclusion}
\label{sec:five}

In summary, we developed a streamlined framework to evaluate any regression and
classification model with a common interface using a variety of different
scoring functions, cross-validation and feature selection methods on a common
data set.  More specifically, provided with the Yelp data set, we successfully
applied machine learning algorithms to optimally solve the above mentioned
tasks.  As part of our pipeline, we determined hyper-parameters for all models
and based on the evaluation chose the best one.

Using feature selection techniques, we selected the best features for our
models; features highly correlated with the target outcome for the regression
task, and features with a high discriminate power for classification.  In both
cases, we found a relatively small number of features to be sufficient for an
optimal performance.

We have successfully bested the baseline for the regression using our own
polynomial regression model implementation, yet barely beat the baseline with
our $k$-Nearest Neighbor classifier and borrowed random forest model.

Going further, we plan to continue developing and expanding our framework for
future model evaluation on different data sets.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
