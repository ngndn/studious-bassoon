\section{Introduction}
\label{sec:one}

The Yelp\furl{https://www.yelp.com/dataset_challenge} data set consists of two
parts meant for two separate machine learning tasks.  One of these tasks being
regression, where, given a word count vector of a review, we predict the number
of positive votes the review has received.  The other task pertains to the
problem of classification.  Here, we label a review as either positive (1) or
negative (0) given the same word count vector.  A positive review has received
an average rating of more than three stars, whereas a negative label indicates a
review of three or fewer stars.

As indicated above, the data sets comprise 50 feature vectors, which correspond
to the word counts for 50 manually selected most frequent words.  Providing this
relatively large number of features, we turn to feature selection algorithms in
order to reduce the model fitting complexity.  We utilize different methods for
the two tasks.  As a central theme for this exercise, we focus on selecting the
optimal number of features and compare the performance of all models using
subsets of the most discriminating features.

The main objective is to beat the performance of a sensibly chosen naive
baseline.  For this purpose, we implement simple, yet powerful machine learning
models.  These perform very well for the regression task and barely manage to
beat the baseline of the classification task.

The implemented models and the experiment framework are discussed in detail in
Section~\ref{sec:two} and~\ref{sec:three}, respectively.  Section~\ref{sec:four}
contains the results of the experiment.  We conclude this report with a brief
conclusion in Section~\ref{sec:five}.  A complete list of all features and their
respective selection test scores for each task can be found in
Appendix~\ref{app:feature-list}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
